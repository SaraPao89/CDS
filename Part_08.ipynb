{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn\n",
    "- a free software machine learning library\n",
    "- various classification, regression and clustering algorithms\n",
    "- built on NumPy, SciPy, and matplotlib\n",
    "\n",
    "In Scikit-learn classifiers are Python objects. They are trained and evaluated using methods implemented by all classifier objects.\n",
    "\n",
    "We start by importing a number of libraries and modules that we will be using in this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Tools for scaling data, PCA, and standard datasets\n",
    "from sklearn import preprocessing, decomposition, datasets\n",
    "\n",
    "# Tools for tracking learning curves and perform cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, validation_curve, learning_curve\n",
    "\n",
    "# The k-NN learning algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load in memory the *Breast Cancer Wisconsin (Diagnostic) Data Set*, a dataset for binary classification. The labels are `M` (malignant cancer) and `B` (benign cancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv(\"../Datasets/cancer.csv\")\n",
    "cancer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the dataset we note that the first column (`id`) and the last column can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the last column contains all `Nan`, and there are not other `Nan` values in the dataset, we can delete it using the `dropna()` method invoked over the columns. This deletes any column that contains at least a `Nan` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = cancer.dropna(axis='columns')\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the set of instances by dropping the column `id` and by dropping the column `diagnosis` containing the labels. We do this using the method `drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop(columns=['id', 'diagnosis']).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we replace the categorical labels `B` and `M` with numerical labels `0` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_int = {'B' : 0, 'M' : 1}\n",
    "cancer['diagnosis'] = cancer['diagnosis'].map(str_to_int)\n",
    "np.unique(cancer['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to use the new values in the column `diagnoses` as vector of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancer['diagnosis'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Numpy function `unique()` with the flag `return_counts` set, we can see the number of examples in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to randomly split the dataset in training and test sets. Since the dataset is relatively small (569 points), we leave 40% of the data for testing. The `random_state` variable is used a seed (we choose 42 just as any other value) for the random number generator in case we want to repeat the experiment using the same random bits. The flag `stratify` creates a split with the same proportion of classes in the train and test sets (especially useful when datasets are unbalanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a classifier for this dataset. We create a $1$-NN classifier object by invoking the function `kNN(n_neighbors=1)`, where `kNN()` is the alias we created when we imported the module for `KNeighborsClassifier()`. The object is assigned to the variable `knn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = kNN(n_neighbors=1)\n",
    "type(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the 1-NN classifier by invoking the method `fit()` with training points and training labels as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we invoke the method `score()` to evaluate the accuracy of the trained model on both the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the training accuracy is 1 (i.e., zero training error) while the testing accuracy is way below.\n",
    "\n",
    "We perform a second experiment on the same random split this time using 3-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = kNN(n_neighbors=3) # 3-NN\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictably, the training accuracy went down (by about 5%), while the test accuracy is now pretty close to the training accuracy.\n",
    "\n",
    "Next, we use the function `learning_curve()` to inspect the evolution of training and test performance of $7$-NN for increasing sizes of the training set.\n",
    "\n",
    "For each value of the training set size, a 5-fold stratified cross-validation is performed to estimate the risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = range(100, 401, 50)\n",
    "train_size, train_score, val_score = learning_curve(kNN(n_neighbors=7), X, y, train_sizes=sizes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`val_score` is a matrix whose each row contains the accuracy on the $5$ folds of cross validation for a given value of training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and cross-validation scores are plotted as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('7-NN vs. training size')\n",
    "plt.plot(train_size, np.mean(val_score, 1), label='Validation accuracy')\n",
    "plt.plot(train_size, np.mean(train_score, 1), label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the training and test performance in terms of the parameter $k$ of $k$-NN. We start by creating a list of values of $k$ from 1 to 200 with steps of 20.\n",
    "\n",
    "Then, we use the function `validation_curve()` to create a matrix of training scores and a matrix of test scores, where, as before, rows are indexed by the values of $k$ used to generate the scores, and columns report the per-fold performance in a cross-validation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = range(1,200,20)\n",
    "train_score, val_score = validation_curve(kNN(), X, y, 'n_neighbors', neighbors, cv=5)\n",
    "train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results clearly reveals overfitting and underfitting regions of the parameter $k$, with the best value at about $k=25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('k-NN vs. number of neighbors')\n",
    "plt.plot(neighbors, np.mean(val_score, 1), label='Testing accuracy')\n",
    "plt.plot(neighbors, np.mean(train_score, 1), label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move on to a different dataset: the *Pima Indians Diabetes Database*. The goal of this dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Hence, the are only two labels (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pima = pd.read_csv(\"Datasets/diabetes.csv\")\n",
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Outcome` column contains the labels. We use this to construct our sets of training points and training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima.drop(columns='Outcome').values\n",
    "y = pima['Outcome'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we count the proportions of positive and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the dataset in training set (60%) and test set (40%) using stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation curve is plotted using the same range of values for $k$ as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = range(1,200,20)\n",
    "train_score, val_score = validation_curve(kNN(), X, y, 'n_neighbors', neighbors, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, the regions of underfitting and overfitting for the parameter $k$ are clearly seen in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('k-NN vs. number of neighbors')\n",
    "plt.plot(neighbors, np.mean(val_score, 1), label='Testing accuracy')\n",
    "plt.plot(neighbors, np.mean(train_score, 1), label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to evaluate performance of a given algorithm\n",
    "The function `cross_val_score()` performs cross validation to estimate the risk of the classifier output by a given algorithm.\n",
    "\n",
    "Here is an example using $5$-fold cross-validation on the entire dataset to evaluate the performance of $21$-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = kNN(n_neighbors=21)\n",
    "scores = cross_val_score(knn, X, y, cv=5)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-search to find best value of parameter for the learning algorithm\n",
    "We can use the function `GridSearch()` to look for the best parameter of an algorithm using the entire dataset.\n",
    "- Repeat 5-fold cross-validation on the entire dataset for each value of the parameter in the grid\n",
    "- Select the parameter with the best cross-validated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grid = {'n_neighbors': range(1, 100, 20)}\n",
    "learner = GridSearchCV(estimator=kNN(), param_grid=k_grid, cv=5, return_train_score=True)\n",
    "learner.fit(X, y)\n",
    "learner.best_params_, learner.best_score_ # vars containing the best parameter value and its corresponding cv score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm with the best parameter, $21$-NN, is available in the variable `learner.best_estimator_`, that is `learner.best_estimator_ = kNN(n_neighbors=21)`\n",
    "\n",
    "We repeat the evaluation of this algorithm using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.best_estimator_\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested cross-validation to evaluate performance of a learning algorithm with parameters to tune\n",
    "We saw that cross-validation allows us to use the data for choosing a good value of the parameter. However, we are still left with the problem of estimating the risk of the classifier generated by the algorithm. Nested cross-validation provides a way of estimating the risk of a classifier generated by an algorithm whose parameters are tuned using cross-validation on the training set.\n",
    "\n",
    "In the following example, we:\n",
    "- Run 5-fold cross-validation on the entire dataset\n",
    "- On the training part of each fold, run *internal* 5-fold cross-validation to find the best value of the parameter\n",
    "- Re-train the model on the training part of the outer fold using the optimized parameter\n",
    "- Test the model on the testing part of the outer fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_grid = {'n_neighbors': range(1,100,20)}\n",
    "learner = GridSearchCV(estimator=kNN(), param_grid=k_grid, cv=5) # internal C-V\n",
    "scores = cross_val_score(learner, X, y, cv=5) # external C-V\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the nested cross-validated estimate is $0.72$, while the cross-validated estimate we computed above using grid search on the entire dataset is higher, $0.74$. This discrepancy occurs because nested CV runs grid search on the smaller nested folds. On the other hand, the nested CV estimate is statistically more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset\n",
    "Many learning algorithms may work better when the training set is rescaled in certain ways. Note that, in order to avoid contributing to overfitting, these rescalings should not depend on the training labels.\n",
    "\n",
    "We illustrate the most popular rescaling technique on the cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop(columns=['id', 'diagnosis']).values\n",
    "y = cancer['diagnosis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StandardScaler()` function standardizes the values of each feature $i$. If $x_1(i),\\ldots,x_m(i)$ are the values of the $i$-th feature in the dataset $x(1),\\dots,x(m)$, then `StandardScaler()` replaces each value $x_t(i)$ with\n",
    "$$x_t(i)' = \\frac{x_t(i)-\\mu_i}{\\sigma_i}$$\n",
    "where $$\\mu_i = \\frac{1}{m}\\sum_{t=1}^m x_t(i) \\;\\;\\;\\textrm{and}\\;\\;\\; \\sigma_i^2 = \\frac{1}{m}\\sum_{t=1}^m \\bigl(x_t(i)-\\mu_i\\big)^2$$\n",
    "\n",
    "Note that `standard_scaler.fit_transform()` is used to compute $\\mu_i$ and $\\sigma_i$ for each feature $i$ on the training data and then to rescale the training data. The testing data are rescaled using the parameters computed on the training data. Allowing the learner to compute the rescaling parameters using the testing data would imply that the test set is made available (without labels) before the classifier is generated. This is typically not allowed in the statistical learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the test set performance with and without rescaling for different values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = range(1,8)\n",
    "test_scores = []\n",
    "test_scores_standard = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = kNN(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "    knn.fit(X_train_standard, y_train)\n",
    "    test_scores_standard.append(knn.score(X_test_standard, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the perfomance in both cases shows the benefits of rescaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('k-NN vs. number of neighbors')\n",
    "plt.plot(neighbors, test_scores, label='Testing accuracy')\n",
    "plt.plot(neighbors, test_scores_standard, label='Testing accuracy (scaled)')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the same exercise use the Pima Indians dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima.drop(columns='Outcome').values\n",
    "y = pima['Outcome'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42, stratify=y)\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = range(1,100,20)\n",
    "test_scores = []\n",
    "test_scores_standard = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = kNN(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "    knn.fit(X_train_standard, y_train)\n",
    "    test_scores_standard.append(knn.score(X_test_standard, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case, we see that rescaling helps boost the test accuracy when $k$ is not chosen optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('k-NN vs. number of neighbors')\n",
    "plt.plot(neighbors, test_scores, label='Testing accuracy')\n",
    "plt.plot(neighbors, test_scores_standard, label='Testing accuracy (scaled)')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish by showing a graphical representation of the $k$-NN classifier.\n",
    "\n",
    "We do this by\n",
    "- loading the IRIS dataset using the shortcut provided by the Scikit-learn module `datasets`\n",
    "- projecting the dataset onto the two principal dimension via Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X) # Compute PCA\n",
    "X = pca.transform(X) # Project data onto first two principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot of the projected data reveals that $k$-NN is going to have an easy time classifying this dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell (adapted from https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html) allows us to visualize the decision surface of the $k$-NN classifier. Each colored region is the the set of data points that are assigned the same classification by $k$-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = kNN(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same exercise using the Pima Indians dataset. Note that the job of $k$-NN is harder here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima.drop(columns='Outcome').values\n",
    "y = pima['Outcome'].values\n",
    "\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = kNN(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
